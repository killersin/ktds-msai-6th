import os
import streamlit as st
import json
import requests
import pandas as pd

from dotenv import load_dotenv
from datetime import datetime
from bs4 import BeautifulSoup
from azure.search.documents import SearchClient
from azure.core.credentials import AzureKeyCredential

load_dotenv()

st.set_page_config(
    page_title="KTDS MSAI MVP 616",
    page_icon="ğŸ›¡ï¸"  # ë˜ëŠ” ":robot:" ë˜ëŠ” "https://example.com/favicon.png"
)

if "show_board" not in st.session_state:
    st.session_state["show_board"] = False

# ì‚¬ì´ë“œë°”: ëª¨ë“œ ì„ íƒ(ì¢Œì¸¡í™”ë©´ ë¶„ë¥˜)
mode = st.sidebar.selectbox("ëª¨ë“œ ì„ íƒ", ["ì±—ë´‡", "ì¼ë°˜ê²€ìƒ‰", "Azure Search"])

# ì‚¬ì´ë“œë°”ì— í™ˆìœ¼ë¡œ/ê²Œì‹œê¸€ ë³´ê¸° ë²„íŠ¼ ì¶”ê°€
if st.sidebar.button("í™ˆìœ¼ë¡œ"):
    st.session_state["show_board"] = False

# ê²Œì‹œê¸€ ë³´ê¸° ë²„íŠ¼
if st.sidebar.button("ê²Œì‹œê¸€ ë³´ê¸°"):
    st.session_state["show_board"] = True

if st.session_state["show_board"]:
    # ê²Œì‹œê¸€ ê´€ë ¨ ê¸°ëŠ¥ì„ modules.newssummaryë¡œ ë¶„ë¦¬
    try:
        from modules.newssummary import show_board
        show_board()
    except Exception as e:
        st.error(f"ê²Œì‹œê¸€ ëª¨ë“ˆì„ ë¡œë“œí•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {e}")
else:
    # ëª¨ë“œì— ë”°ë¼ ë©”ì¸ í™”ë©´ ë Œë”ë§
    if mode == "Azure Search":
        # --- Azure Search + RAG ì±—ë´‡ ---
        try:
            search_endpoint = os.getenv("AZURE_SEARCH_ENDPOINT")
            search_key = os.getenv("AZURE_SEARCH_API_KEY") or os.getenv("AZURE_SEARCH_KEY")
            search_index = os.getenv("AZURE_SEARCH_INDEX_NAME") or os.getenv("AZURE_SEARCH_INDEX")
            embedding_deployment = os.getenv("AZURE_EMBEDDING_DEPLOYMENT") or os.getenv("AZURE_OPENAI_EMBEDDING_DEPLOYMENT")

            if not (search_endpoint and search_key and search_index):
                st.info("Azure Search ì„¤ì •ì´ .envì— ì—†ìŠµë‹ˆë‹¤. AZURE_SEARCH_ENDPOINT, AZURE_SEARCH_API_KEY, AZURE_SEARCH_INDEX_NAMEì„ ì„¤ì •í•˜ì„¸ìš”.")
            else:
                st.markdown("## RAG ì±—ë´‡ (Azure Search)")
                # Chat UI reused
                from langchain_openai import AzureChatOpenAI
                model = AzureChatOpenAI(
                    azure_endpoint=os.getenv("AZURE_ENDPOINT"),
                    api_key=os.getenv("OPENAI_API_KEY"),
                    api_version=os.getenv("AZURE_OPENAI_VERSION"),
                    azure_deployment=os.getenv("AZURE_CHAT_DEPLOYMENT") or "gpt-4.1-mini"
                )

                # ensure messages
                if "messages" not in st.session_state:
                    st.session_state["messages"] = [{"role": "system", "content": "You are a helpful assistant."}]

                # show history
                for msg in st.session_state["messages"]:
                    with st.chat_message(msg["role"]):
                        st.markdown(msg["content"])

                # user input
                if prompt := st.chat_input("User : "):
                    st.session_state["messages"].append({"role": "user", "content": prompt})
                    with st.chat_message("user"):
                        st.markdown(prompt)

                    # Prepare Azure Search client
                    credential = AzureKeyCredential(search_key)
                    search_client = SearchClient(endpoint=search_endpoint, index_name=search_index, credential=credential)

                    # Try to compute embedding for the query (Azure OpenAI) for vector search
                    embedding_vector = None
                    if embedding_deployment:
                        try:
                            import importlib
                            oa_mod = importlib.import_module("azure.ai.openai")
                            OpenAIClient = getattr(oa_mod, "OpenAIClient")
                            from azure.core.credentials import AzureKeyCredential as CoreAzureKey
                            oa_key = os.getenv("OPENAI_API_KEY") or os.getenv("AZURE_OPENAI_KEY") or os.getenv("AZURE_OPENAI_API_KEY")
                            oa_endpoint = os.getenv("AZURE_ENDPOINT")
                            if oa_key and oa_endpoint:
                                oa_client = OpenAIClient(oa_endpoint, CoreAzureKey(oa_key))
                                emb_resp = oa_client.embeddings.create(model=embedding_deployment, input=prompt)
                                embedding_vector = emb_resp.data[0].embedding
                        except Exception:
                            # embedding client not available or failed â€” fallback to text search
                            embedding_vector = None

                    top_k = int(st.session_state.get("rag_top_k", 5))

                    retrieved_docs = []
                    try:
                        if embedding_vector is not None:
                            # vector search
                            try:
                                results = search_client.search(search_text="*", vector={"value": embedding_vector, "fields": "content_vector", "k": top_k})
                            except TypeError:
                                # older SDK shape
                                results = search_client.search(search_text="", vector={"value": embedding_vector, "fields": "content_vector", "k": top_k})
                        else:
                            # fallback to text search
                            results = search_client.search(search_text=prompt, top=top_k)

                        for r in results:
                            doc = {
                                "id": r.get("id") or r.get("@search.documentId") or None,
                                "category": r.get("category") or r.get("title") or "",
                                "content": r.get("content") or r.get("text") or "",
                                "score": r.get("@search.score")
                            }
                            retrieved_docs.append(doc)
                    except Exception as e:
                        st.error(f"Azure Search ì¡°íšŒ ì‹¤íŒ¨: {e}")

                    # Display retrieved docs
                    if retrieved_docs:
                        st.subheader(f"ê²€ìƒ‰ ê²°ê³¼ ({len(retrieved_docs)})")
                        for d in retrieved_docs:
                            with st.expander(f"{d.get('category')} â€” {d.get('score')}"):
                                st.write(d.get("content"))

                    # Build context from retrieved docs and ask model
                    context_text = "\n\n".join([f"[ì¶œì²˜ {i+1}] {d.get('content')}" for i, d in enumerate(retrieved_docs)])
                    if context_text:
                        system_context = {
                            "role": "system",
                            "content": "ë‹¤ìŒì€ ê²€ìƒ‰ëœ ë¬¸ì„œë“¤ì…ë‹ˆë‹¤. ì‚¬ìš©ì ì§ˆë¬¸ì— ë‹µí•  ë•Œ ì´ ë‚´ìš©ì„ ì°¸ê³ í•˜ì„¸ìš”:\n" + context_text
                        }
                        # construct messages with context injected before the user message
                        messages_for_model = [m for m in st.session_state["messages"]]
                        # insert system_context right before last user message
                        messages_for_model.insert(len(messages_for_model)-1, system_context)
                    else:
                        messages_for_model = st.session_state["messages"]

                    # Call model (stream)
                    response_text = ""
                    with st.chat_message("assistant"):
                        placeholder = st.empty()
                        try:
                            for chunk in model.stream(messages_for_model):
                                response_text += chunk.content
                                placeholder.markdown(response_text)
                        except Exception as e:
                            st.error(f"ëª¨ë¸ í˜¸ì¶œ ì¤‘ ì˜¤ë¥˜: {e}")

                    st.session_state["messages"].append({"role": "assistant", "content": response_text})
        except Exception as e:
            st.error(f"ê²€ìƒ‰ UI ì´ˆê¸°í™” ì˜¤ë¥˜: {e}")

    elif mode == "ì¼ë°˜ê²€ìƒ‰":
        # --- ë¡œì»¬ JSON ê¸°ë°˜ ë‹¨ìˆœ ê²€ìƒ‰ ---
        st.markdown("## ë¡œì»¬ ë¬¸ì„œ ê²€ìƒ‰")
        q = st.text_input("ê²€ìƒ‰ì–´ (ë¡œì»¬ ë°ì´í„°)", key="local_search_query")
        top_k = st.number_input("ìµœëŒ€ ê²°ê³¼ìˆ˜", min_value=1, max_value=50, value=10)
        if q:
            # í›„ë³´ íŒŒì¼ ë¡œë“œ
            candidates = [
                os.path.join("data", "9_field.json"),
                os.path.join("data", "9_domains.json"),
                os.path.join("data", "test.json"),
            ]
            data = None
            for p in candidates:
                if os.path.exists(p):
                    try:
                        with open(p, "r", encoding="utf-8") as f:
                            data = json.load(f)
                            break
                    except Exception:
                        continue

            if data is None:
                st.warning("ë¡œì»¬ ë°ì´í„° íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. data/*.json íŒŒì¼ì„ í™•ì¸í•˜ì„¸ìš”.")
            else:
                # ë¬¸ì„œ ë¦¬ìŠ¤íŠ¸ ìƒì„±
                docs = []
                if isinstance(data, dict):
                    for cat, items in data.items():
                        for idx, item in enumerate(items):
                            docs.append({"id": f"{cat}-{idx}", "category": cat, "content": item})
                elif isinstance(data, list):
                    for idx, item in enumerate(data):
                        if isinstance(item, dict):
                            docs.append({"id": item.get("id") or f"item-{idx}", "category": item.get("category"), "content": item.get("content")})
                        else:
                            docs.append({"id": f"item-{idx}", "category": None, "content": str(item)})

                # ê°„ë‹¨í•œ ì„œë¸ŒìŠ¤íŠ¸ë§ ê²€ìƒ‰
                ql = q.lower()
                matches = [d for d in docs if d.get("content") and ql in d.get("content").lower()]
                st.subheader(f"{len(matches)}ê°œì˜ ê²°ê³¼")
                for m in matches[:top_k]:
                    with st.expander(f"{m.get('category') or 'í•­ëª©'} â€” {m.get('id')}"):
                        st.write(m.get("content"))

    else:
        # --- ì±—ë´‡ ê¸°ë³¸ í™”ë©´ ---
        st.title("ktds-msai-6th-mvp ğŸ¤–")
        st.caption("Azure OpenAIì˜ ìµœì‹  GPT-4o-mini ëª¨ë¸ì„ ì‚¬ìš©í•œ ìŠ¤íŠ¸ë¦¬ë° ì±—ë´‡ì…ë‹ˆë‹¤.")
        from langchain_openai import AzureChatOpenAI
        model = AzureChatOpenAI(
            azure_endpoint=os.getenv("AZURE_ENDPOINT"),
            api_key=os.getenv("OPENAI_API_KEY"),
            api_version=os.getenv("AZURE_OPENAI_VERSION"),
            azure_deployment="gpt-4.1-mini"
        )
        if "messages" not in st.session_state:
            st.session_state["messages"] = [
                {"role": "system", "content": "You are a helpful assistant."}
            ]
        for msg in st.session_state["messages"]:
            with st.chat_message(msg["role"]):
                st.markdown(msg["content"])

        if prompt := st.chat_input("User : "):
            st.session_state["messages"].append({"role": "user", "content": prompt})
            with st.chat_message("user"):
                st.markdown(prompt)

            response_text = ""
            with st.chat_message("assistant"):
                placeholder = st.empty()
                for chunk in model.stream(st.session_state["messages"]):
                    response_text += chunk.content
                    placeholder.markdown(response_text)

            st.session_state["messages"].append({"role": "assistant", "content": response_text})