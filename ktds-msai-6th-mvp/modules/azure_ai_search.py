"""
Azure AI Search ëª¨ë“ˆ
RAG íŒŒì´í”„ë¼ì¸ì„ ìœ„í•œ ë²¡í„° ê²€ìƒ‰ ë° ë¬¸ì„œ ì¸ë±ì‹± ë‹´ë‹¹

ì´ ëª¨ë“ˆ ê¸°ëŠ¥:
- Azure Search ì¸ë±ìŠ¤(ì˜ˆ: compliance-9fields) ìƒì„±
- ë¡œì»¬ JSON íŒŒì¼(`/data/9_field.json` ë˜ëŠ” ëŒ€ì²´ ê²½ë¡œ)ì˜ í•­ëª©ì„ ì¸ë±ìŠ¤ì— ì—…ë¡œë“œ

í•„ìš” í™˜ê²½ë³€ìˆ˜:
- AZURE_SEARCH_ENDPOINT
- AZURE_SEARCH_KEY
"""

import os
import json
import logging
from typing import Dict, List, Optional

from azure.core.credentials import AzureKeyCredential
from azure.search.documents import SearchClient
from azure.search.documents.indexes import SearchIndexClient
from azure.search.documents.indexes.models import (
	SearchIndex,
	SearchField,
	SearchFieldDataType,
	SimpleField,
	SearchableField,
	VectorSearch,
	VectorSearchProfile,
	VectorSearchAlgorithmKind,
	VectorSearchAlgorithmMetric,
	HnswAlgorithmConfiguration,
)

from dotenv import load_dotenv

load_dotenv()
logger = logging.getLogger(__name__)
logging.basicConfig(level=logging.INFO)



class AzureSearchClient:
	"""Azure AI Searchì™€ í†µì‹ í•˜ëŠ” ê°„ë‹¨í•œ í´ë¼ì´ì–¸íŠ¸

	ì°¸ê³ :
	- ì…ë ¥ JSON í˜•ì‹ì€ ë‘ ê°€ì§€ ì¤‘ í•˜ë‚˜ë¥¼ ì§€ì›í•©ë‹ˆë‹¤:
	  1) ë¦¬ìŠ¤íŠ¸ í˜•íƒœ: [{"category_no":1, "category":"ë¶€íŒ¨ë°©ì§€", "content":"..."}, ...]
	  2) dict í˜•íƒœ: {"01_ë¶€íŒ¨ë°©ì§€": ["ë‚´ìš©1", "ë‚´ìš©2", ...], ...}
	- í˜„ì¬ ì´ ëª¨ë“ˆì€ ìë™ìœ¼ë¡œ ì„ë² ë”©ì„ ìƒì„±í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤. ì„ë² ë”©ì´ í•„ìš”í•  ê²½ìš° í™˜ê²½ë³€ìˆ˜ë¥¼ í†µí•´ í™œì„±í™”ë©ë‹ˆë‹¤.
	"""

	def __init__(self):
		self.endpoint = os.getenv("AZURE_SEARCH_ENDPOINT")  # Azure Search ì—”ë“œí¬ì¸íŠ¸
		# í‚¤ í™˜ê²½ë³€ìˆ˜ëª… í˜¸í™˜ì„±: AZURE_SEARCH_KEY ë˜ëŠ” AZURE_SEARCH_API_KEY
		self.key = os.getenv("AZURE_SEARCH_KEY") or os.getenv("AZURE_SEARCH_API_KEY")
		# ì¸ë±ìŠ¤ ì´ë¦„ í™˜ê²½ë³€ìˆ˜ë„ ì—¬ëŸ¬ëª… ì§€ì›
		self.index_name = os.getenv("AZURE_SEARCH_INDEX_NAME") or os.getenv("AZURE_SEARCH_INDEX")
		# .envì— ë”°ì˜´í‘œê°€ ë“¤ì–´ê°„ ê²½ìš° ì œê±°
		if self.index_name:
			self.index_name = self.index_name.strip().strip('"').strip("'")

		if not self.endpoint or not self.key:
			raise ValueError("AZURE_SEARCH_ENDPOINT ë˜ëŠ” AZURE_SEARCH_API_KEY/AZURE_SEARCH_KEY í™˜ê²½ë³€ìˆ˜ê°€ í•„ìš”í•©ë‹ˆë‹¤.")

		self.credential = AzureKeyCredential(self.key)
		self.index_client = SearchIndexClient(endpoint=self.endpoint, credential=self.credential)
		logger.info("Azure SearchIndexClient ì´ˆê¸°í™” ì™„ë£Œ")

	def create_compliance_index(self) -> bool:
		"""ì»´í”Œë¼ì´ì–¸ìŠ¤(9ê°œ ë¶„ì•¼)ìš© ì¸ë±ìŠ¤ ìƒì„±

		- content(ê²€ìƒ‰ê°€ëŠ¥), category/ category_no í•„í„° ê°€ëŠ¥
		- content_vector í•„ë“œëŠ” ë²¡í„° ê²€ìƒ‰ì„ ìœ„í•´ ì¤€ë¹„ë˜ì–´ ìˆìŒ(ì„ë² ë”©ì´ ìˆì„ ë•Œ ì—…ë¡œë“œ ê°€ëŠ¥)
		"""
		try:
			vector_search = VectorSearch(
				profiles=[
					VectorSearchProfile(name="default-profile", algorithm_configuration_name="default-hnsw")
				],
				algorithms=[
					HnswAlgorithmConfiguration(
						name="default-hnsw",
						kind=VectorSearchAlgorithmKind.HNSW,
						parameters={
							"m": 4,
							"efConstruction": 400,
							"efSearch": 500,
							"metric": VectorSearchAlgorithmMetric.COSINE,
						},
					)
				],
			)

			fields = [
				SimpleField(name="id", type=SearchFieldDataType.String, key=True),
				SimpleField(name="category_no", type=SearchFieldDataType.Int32, filterable=True, sortable=True),
				SimpleField(name="category", type=SearchFieldDataType.String, filterable=True),
				SimpleField(name="domain", type=SearchFieldDataType.String, filterable=True),
				SearchableField(name="content", type=SearchFieldDataType.String, analyzer_name=None),
				SimpleField(name="source", type=SearchFieldDataType.String, filterable=True, facetable=False),
				SimpleField(name="item_index", type=SearchFieldDataType.Int32, filterable=True, sortable=True),
				SearchField(
					name="content_vector",
					type=SearchFieldDataType.Collection(SearchFieldDataType.Single),
					searchable=True,
					vector_search_dimensions=1536,
					vector_search_profile_name="default-profile",
				),
			]

			index = SearchIndex(name=self.index_name, fields=fields, vector_search=vector_search)

			result = self.index_client.create_or_update_index(index)
			logger.info(f"ì¸ë±ìŠ¤ ìƒì„±/ì—…ë°ì´íŠ¸ ì™„ë£Œ: {result.name}")
			return True

		except Exception as e:
			logger.exception("ì¸ë±ìŠ¤ ìƒì„± ì‹¤íŒ¨")
			return False

	def get_search_client(self) -> SearchClient:
		return SearchClient(endpoint=self.endpoint, index_name=self.index_name, credential=self.credential)

	def ensure_index_exists(self) -> bool:
		"""ì¸ë±ìŠ¤ ì¡´ì¬ ì—¬ë¶€ í™•ì¸ í›„ ì—†ìœ¼ë©´ ìƒì„±í•œë‹¤."""
		try:
			# ì¸ë±ìŠ¤ ì¡´ì¬ ì—¬ë¶€ í™•ì¸
			self.index_client.get_index(self.index_name)
			logger.info(f"ì¸ë±ìŠ¤ê°€ ì´ë¯¸ ì¡´ì¬í•©ë‹ˆë‹¤: {self.index_name}")
			return True
		except Exception:
			logger.info(f"ì¸ë±ìŠ¤ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ìƒì„±ì„ ì‹œë„í•©ë‹ˆë‹¤: {self.index_name}")
			return self.create_compliance_index()

	def _load_json_candidates(self, paths: List[str]) -> Optional[object]:
		"""ì—¬ëŸ¬ í›„ë³´ ê²½ë¡œì—ì„œ ì²« ë²ˆì§¸ë¡œ ì¡´ì¬í•˜ëŠ” JSONì„ ë¡œë“œí•˜ì—¬ ë°˜í™˜"""
		for p in paths:
			if os.path.exists(p):
				try:
					with open(p, "r", encoding="utf-8") as f:
						return json.load(f)
				except Exception:
					logger.exception(f"JSON ë¡œë“œ ì‹¤íŒ¨: {p}")
		return None

	def index_from_file(self, file_path: str = None, batch_size: int = 200) -> Dict:
		"""ë¡œì»¬ JSON íŒŒì¼ì„ ì½ì–´ ì¸ë±ìŠ¤ì— ì—…ë¡œë“œ
		2) ./data/9_field.json
		"""
		candidates = []
		if file_path:
			candidates.append(file_path)
		candidates.extend([
			os.path.join("data", "9_field.json")
		])

		data = self._load_json_candidates(candidates)
		if data is None:
			raise FileNotFoundError("ì¸ë±ì‹±í•  JSON íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. í›„ë³´: " + ",".join(candidates))

	# JSONì„ ë¬¸ì„œ ëª©ë¡ í˜•ì‹ìœ¼ë¡œ ë³€í™˜
		docs = []
		if isinstance(data, dict):
			# í˜•íƒœ: {"01_ë¶€íŒ¨ë°©ì§€": [...], ...}
			for cat_key, items in data.items():
				for idx, item in enumerate(items):
					docs.append({
						"id": f"{cat_key}-{idx}",
						"category": cat_key,
						"category_no": None,
						"content": item,
						"source": os.path.basename(candidates[0]),
						"item_index": idx,
					})
		elif isinstance(data, list):
			# ë¦¬ìŠ¤íŠ¸ì˜ ê° í•­ëª©ì´ dict(ì´ë¯¸ êµ¬ì¡°í™”)ì¸ ê²½ìš°
			for idx, item in enumerate(data):
				if isinstance(item, dict):
					cid = item.get("id") or f"{item.get('category_no','')}-{idx}"
					docs.append({
						"id": str(cid),
						"category": item.get("category") or item.get("category", ""),
						"category_no": item.get("category_no"),
						"domain": item.get("domain"),
						"content": item.get("content") or item.get("text") or json.dumps(item, ensure_ascii=False),
						"source": os.path.basename(candidates[0]),
						"item_index": idx,
					})
				else:
					# ë‹¨ìˆœ ë¬¸ìì—´ ë¦¬ìŠ¤íŠ¸ ì²˜ë¦¬
					docs.append({
						"id": f"item-{idx}",
						"category": None,
						"category_no": None,
						"content": str(item),
						"source": os.path.basename(candidates[0]),
						"item_index": idx,
					})
		else:
			raise ValueError("ì§€ì›ë˜ì§€ ì•ŠëŠ” JSON êµ¬ì¡°ì…ë‹ˆë‹¤.")

	# ë°°ì¹˜ ì—…ë¡œë“œ ì „ ì¶”ê°€ ì²˜ë¦¬
	# --- ì¹´í…Œê³ ë¦¬ë³„ í†µí•©(doc per category) ë¬¸ì„œ ìƒì„± ---
	# ê°™ì€ ì¹´í…Œê³ ë¦¬ì˜ contentë“¤ì„ í•©ì³ ë³„ë„ì˜ ìš”ì•½/ì§‘ê³„ ë¬¸ì„œë¥¼ ìƒì„±í•˜ë©´
	# "ì»´í”Œë¼ì´ì–¸ìŠ¤ 9ëŒ€ë¶„ì•¼ ì„¤ëª…í•´ì¤˜" ê°™ì€ ì§ˆë¬¸ì— ë” ì í•©í•œ ì»¨í…ìŠ¤íŠ¸ê°€ ë©ë‹ˆë‹¤.
		agg_map = {}
		for d in docs:
			cat_key = d.get("category") or str(d.get("category_no")) or "unknown"
			agg_map.setdefault(cat_key, []).append(d.get("content", ""))

		for cat, pieces in agg_map.items():
			# ê¸°ì¡´ ë¬¸ì„œì—ì„œ ëŒ€í‘œ category_noë¥¼ ê°€ì ¸ì˜¤ë ¤ê³  ì‹œë„
			cat_no = None
			for d in docs:
				if d.get("category") == cat and d.get("category_no") is not None:
					cat_no = d.get("category_no")
					break

			agg_doc = {
				"id": f"cat-{cat_no or cat}",
				"category": cat,
				"category_no": cat_no,
				"domain": "ì»´í”Œë¼ì´ì–¸ìŠ¤ 9ëŒ€ë¶„ì•¼",
				"content": "\n\n".join(pieces),
				"source": os.path.basename(candidates[0]),
				"item_index": -1,
			}
			docs.append(agg_doc)

	# ë°°ì¹˜ ì—…ë¡œë“œ ì¤€ë¹„

	# --- ì„ë² ë”© ìƒì„±(ì„ íƒ) ---
	# í™˜ê²½ë³€ìˆ˜ë¡œ ì„ë² ë”© ëª¨ë¸/ì—”ë“œí¬ì¸íŠ¸/í‚¤ê°€ ì„¤ì •ë˜ì–´ ìˆìœ¼ë©´
	# ê° ë¬¸ì„œì— 'content_vector' í•„ë“œë¥¼ ì¶”ê°€í•©ë‹ˆë‹¤. ì‹¤íŒ¨í•˜ë©´ ë²¡í„° ì—†ì´ ì—…ë¡œë“œí•©ë‹ˆë‹¤.
		embedding_model = os.getenv("AZURE_EMBEDDING_DEPLOYMENT") or os.getenv("AZURE_OPENAI_EMBEDDING_DEPLOYMENT")
		oa_key = os.getenv("OPENAI_API_KEY") or os.getenv("AZURE_OPENAI_KEY") or os.getenv("AZURE_OPENAI_API_KEY")
		oa_endpoint = os.getenv("AZURE_ENDPOINT") or os.getenv("AZURE_OPENAI_ENDPOINT")

		if embedding_model and oa_key and oa_endpoint:
			try:
				emb_client = OpenAIClient(oa_endpoint, AzureKeyCredential(oa_key))
				# ì‘ì€ ë°°ì¹˜ë¡œ ë‚˜ëˆ  ì„ë² ë”© ìƒì„±
				chunk = 20
				for i in range(0, len(docs), chunk):
					inputs = [d.get("content", "") for d in docs[i : i + chunk]]
					try:
						resp = emb_client.embeddings.create(model=embedding_model, input=inputs)
						for j, item in enumerate(resp.data):
							vec = item.embedding
								# í•´ë‹¹ ë¬¸ì„œì— ë²¡í„° í• ë‹¹
							docs[i + j]["content_vector"] = vec
					except Exception:
						logger.exception("ì„ë² ë”© ìƒì„± ì¤‘ ì˜¤ë¥˜ ë°œìƒ(í•´ë‹¹ ë°°ì¹˜ëŠ” ê±´ë„ˆëœë‹ˆë‹¤)")
						# ì´ ë°°ì¹˜ëŠ” ë²¡í„° ì—†ì´ ê³„ì† ì§„í–‰
						continue
			except Exception:
				logger.exception("ì„ë² ë”© í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™” ì‹¤íŒ¨ - ë²¡í„°ë¥¼ ìƒì„±í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.")
		else:
			logger.info("ì„ë² ë”© í™˜ê²½ë³€ìˆ˜ ë¯¸ì„¤ì • - content_vectorë¥¼ ìƒì„±í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.")

	# ë°°ì¹˜ ì—…ë¡œë“œ
	# ì¸ë±ìŠ¤ ì¡´ì¬ í™•ì¸(ì—†ìœ¼ë©´ ìƒì„±)
		self.ensure_index_exists()
		client = self.get_search_client()
		total = len(docs)
		success = 0
		failed = 0
		for i in range(0, total, batch_size):
			batch = docs[i : i + batch_size]
			try:
				result = client.upload_documents(documents=batch)
				for r in result:
					if getattr(r, "succeeded", False):
						success += 1
					else:
						failed += 1
						logger.error(f"ì—…ë¡œë“œ ì‹¤íŒ¨: {getattr(r, 'error_message', r)}")
			except Exception:
				logger.exception("ë°°ì¹˜ ì—…ë¡œë“œ ì¤‘ ì˜¤ë¥˜")
				failed += len(batch)

		return {"total": total, "success": success, "failed": failed}


def main_create_and_index(file_path: str = None):
	client = AzureSearchClient()
	print("ğŸ”„ ì¸ë±ìŠ¤ ìƒì„±ì¤‘...")
	if client.create_compliance_index():
		print("âœ… ì¸ë±ìŠ¤ ìƒì„±/ì—…ë°ì´íŠ¸ ì™„ë£Œ")
	else:
		print("âŒ ì¸ë±ìŠ¤ ìƒì„± ì‹¤íŒ¨")

	print("ğŸ”„ íŒŒì¼ì„ ì¸ë±ì‹± ì¤‘ì…ë‹ˆë‹¤...")
	try:
		res = client.index_from_file(file_path=file_path)
		print(f"âœ… ì¸ë±ì‹± ì™„ë£Œ: ì´={res['total']}, ì„±ê³µ={res['success']}, ì‹¤íŒ¨={res['failed']}")
	except Exception as e:
		print(f"âŒ ì¸ë±ì‹± ì‹¤íŒ¨: {e}")


if __name__ == "__main__":
	# ìŠ¤í¬ë¦½íŠ¸ë¡œ ì‹¤í–‰í•  ë•Œ ê¸°ë³¸ ê²½ë¡œ ì‚¬ìš©
	main_create_and_index()


